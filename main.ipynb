{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scraper.reddit_scraper import get_reddit_object, get_qa_object, \\\n",
    "                                   get_trump_reddit_posts_and_comments, \\\n",
    "                                    get_kamala_reddit_posts_and_comments, \\\n",
    "                                    read_paths_create_df\n",
    "from utilities.util import create_folder_if_not_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter file paths if necessary\n",
    "REDDIT_SAVE_DIR = './data/reddit/'\n",
    "YOUTUBE_SAVE_DIR = './data/youtube/'\n",
    "FINAL_FILE_SAVE_DIR = './data/'\n",
    "\n",
    "CONSOLIDATED_REDDIT_COMMENT_SAVE_FILE = f'{REDDIT_SAVE_DIR}/consolidated_reddit_comments.csv'\n",
    "CONSOLIDATED_REDDIT_POST_SAVE_FILE = f'{REDDIT_SAVE_DIR}/consolidated_reddit_posts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [REDDIT_SAVE_DIR, YOUTUBE_SAVE_DIR, FINAL_FILE_SAVE_DIR]:\n",
    "    create_folder_if_not_exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "reddit = get_reddit_object()\n",
    "qa_obj = get_qa_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDDIT_POST_TO_SCRAPE = 1 # Change to alter number of posts to scrape comments from\n",
    "trump_post_df, trump_comment_df = get_trump_reddit_posts_and_comments(reddit, qa_obj, REDDIT_SAVE_DIR, max_posts_to_collect=REDDIT_POST_TO_SCRAPE)\n",
    "kamala_post_df, kamala_comment_df = get_kamala_reddit_posts_and_comments(reddit, qa_obj, REDDIT_SAVE_DIR, max_posts_to_collect=REDDIT_POST_TO_SCRAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_reddit_comment_file_paths = [REDDIT_SAVE_DIR+file for file in os.listdir(REDDIT_SAVE_DIR) if '_comment_data_' in file and 'test' not in file]\n",
    "scraped_reddit_post_file_paths = [REDDIT_SAVE_DIR+file for file in os.listdir(REDDIT_SAVE_DIR) if '_post_data_' in file and 'test' not in file]\n",
    "\n",
    "scraped_reddit_comment_df = read_paths_create_df(scraped_reddit_comment_file_paths)\n",
    "scraped_reddit_comment_df.to_csv(CONSOLIDATED_REDDIT_COMMENT_SAVE_FILE, index=False)\n",
    "scraped_reddit_post_df = read_paths_create_df(scraped_reddit_post_file_paths)\n",
    "scraped_reddit_post_df.to_csv(CONSOLIDATED_REDDIT_POST_SAVE_FILE, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
